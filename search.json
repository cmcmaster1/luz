[{"path":"/LICENSE.html","id":"mit-license","dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 luz authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/get-started.html","id":"training-a-nn_module","dir":"Articles","previous_headings":"","what":"Training a nn_module","title":"Get started with Luz","text":"Luz tries reuse much possible existing structures Torch. example, model Luz defined identically define using raw Torch. example, definition feedforward CNN can used classify digits MNIST dataset. can now train model train_dl validate test_dl torch::dataloaders() : Let’s understand happens chunk code: setup function allows configure loss (objective) function optimizer use train model. Optionally can pass list metrics tracked training procedure. Note: loss function can function taking input target tensors returning scalar tensor value optimizer can core Torch optimizer custom ones created torch::optimizer() function. fit method take model specification provided setup() run training procedure using specified training validation torch::dataloaders() well number epochs. Note: reuse core Torch data structures, instead providing data loading functionality. returned object fitted contains trained model well record metrics losses produced training. can also used producing predictions evaluating trained model datasets. fitting, Luz use fastest possible accelerator, ie. CUDA capable GPU available used otherwise fallback CPU. also automatically moves data, optimizers models selected device don’t need handle manually - general error prone. create predictions trained model can use predict method:","code":"net <- nn_module(   \"Net\",   initialize = function() {     self$conv1 <- nn_conv2d(1, 32, 3, 1)     self$conv2 <- nn_conv2d(32, 64, 3, 1)     self$dropout1 <- nn_dropout2d(0.25)     self$dropout2 <- nn_dropout2d(0.5)     self$fc1 <- nn_linear(9216, 128)     self$fc2 <- nn_linear(128, 10)   },   forward = function(x) {     x <- self$conv1(x)     x <- nnf_relu(x)     x <- self$conv2(x)     x <- nnf_relu(x)     x <- nnf_max_pool2d(x, 2)     x <- self$dropout1(x)     x <- torch_flatten(x, start_dim = 2)     x <- self$fc1(x)     x <- nnf_relu(x)     x <- self$dropout2(x)     x <- self$fc2(x)     x   } ) fitted <- net %>%   setup(     loss = nn_cross_entropy_loss(),     optimizer = optim_adam,     metrics = list(       luz_metric_accuracy     )   ) %>%   fit(train_dl, epochs = 10, valid_data = test_dl) predictions <- predict(fitted, test_dl)"},{"path":"/articles/get-started.html","id":"the-training-loop","dir":"Articles","previous_headings":"","what":"The training loop","title":"Get started with Luz","text":"now general idea use fit function now ’s important overview ’s happening inside . pseudocode, ’s fit . fully detailed help build intuition:","code":"# -> Initialize objects: model, optimizers. # -> Select fitting device. # -> Move data, model, optimizers to the selected device. # -> Start training for (epoch in 1:epochs) {   # -> Training procedure   for (batch in train_dl) {     # -> Calculate model `forward` method.     # -> Calulate the loss     # -> Update weights     # -> Update metrics and tracking loss   }   # -> Validation procedure   for (batch in valid_dl) {     # -> Calculate model `forward` method.     # -> Calulate the loss     # -> Update metrics and tracking loss   } } # -> End training"},{"path":"/articles/get-started.html","id":"customizing-with-callbacks","dir":"Articles","previous_headings":"","what":"Customizing with callbacks","title":"Get started with Luz","text":"Luz provides different ways customize training progress depending level control need training loop. fastest way ‘reusable’, sense can create training modification can used many different situations via callbacks. training loop Luz many breakpoints can call arbitrary R functions. functionality allows customize training process without modify general training logic. Luz implements 3 default callbacks occur every training procedure: train-eval callback: Set’s model train() eval() depending procedure training validation. metrics callback: evaluate metrics training validation process. progress callback: implements progress bar prints progress information training. can also implement custom callbacks modify act specifically training procedure. example, let’s implement callback prints ‘Iteration n’ (n iteration number) every batch training set ‘Done’ epoch finished. task use luz_callback function: luz_callback() takes named list function argument name indicate moment callback called. instance on_train_batch_end() called every batch end training procedure on_epoch() end called end every epoch. callback defined can passed fit function via callbacks parameter, eg: Callbacks can called many different positions training loop, including combinations . ’s overview possible callback breakpoints: Every step market on_* point training procedure available callbacks called. important part callbacks ctx (context) object. ctx object used Luz share information training loop callbacks (see future can also used share information model methods metrics). default, ctx object include following information: verbose: value (TRUE FALSE) attributed verbose argument fit . accelerator: Accelerator object used query correct device place models, data, etc. assumes value passed accelerator parameter fit. model: Initialized nn_module object trained fit procedure. optimizers: named list optimizers used training. data: Dataloader passed data argument fit. Modified yield data selected device. valid_data: Dataloader passed valid_data argument fit. Modified yield data selected device. epochs: Total number epochs model trained . epoch: Current training epoch. iter: Current training iteration. ’s reset every epoch going training validation. training: Whether model training validation mode. callbacks: List callbacks called training procedure. ’s union list passed callbacks parameter default callbacks. step: Closure used one step model. ’s used training validation. Takes argument, can access ctx object. call_callbacks: Call callbacks name. example call_callbacks(\"on_train_begin\") call callbacks provide methods point. batch: Last batch obtained dataloader. batch list() 2 elements, one used input target. input: First element last batch obtained current dataloader. target: Second element last batch obtained current dataloader. pred: Last predictions obtained ctx$model$forward . Note: can potentially modified previously ran callbacks. Also note might available used custom training step. loss: Last computed loss model. Note: might available modified training validation step. opt: Current optimizer, ie. optimizer used next step update parameters. opt_nm: Current optimizer name. default ’s opt , can change model uses one optimizer depending set parameters optimized. metrics: list() metric objects updated every on_train_batch_end() on_valid_batch_end(). records list() structure presented filled every epoch record track model training. losses: list() tracking losses time.","code":"print_callback <- luz_callback(   name = \"print_callback\",   on_train_batch_end = function() {     cat(\"Iteration \", ctx$iter, \"\\n\")   },   on_epoch_end = function() {     cat(\"Done!\\n\")   } ) fitted <- net %>%   setup(...) %>%   fit(..., callbacks = list(     print_callback$new()   )) Start Fit    - on_fit_begin   Start Epoch Loop      - on_epoch_begin     Start Train        - on_train_begin       Start Batch Loop          - on_train_batch_begin           Start Default Training Step             - on_train_batch_after_pred             - on_train_batch_after_loss             - on_train_batch_before_backward             - on_train_batch_before_step             - on_train_batch_after_step           End Default Training Step:          - on_train_batch_end       End Batch Loop        - on_train_end     End Train     Start Valid        - on_valid_begin       Start Batch Loop          - on_valid_batch_begin           Start Default Validation Step             - on_valid_batch_after_pred             - on_valid_batch_after_loss           End Default Validation Step          - on_valid_batch_end       End Batch Loop        - on_valid_end     End Valid       - on_epoch_end   End Epoch Loop    - on_fit_end End Fit list(metrics = list(   train = list(     metric1 = list(), # metrics have one element per epoch     metric2 = list()   ),    valid = list(     metric1 = list(),      metric2 = list()   ) ))"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors","text":"Daniel Falbel. Author, maintainer, copyright holder. RStudio. Copyright holder.","code":""},{"path":"/index.html","id":"luz","dir":"","previous_headings":"","what":"Higher Level API for torch","title":"Higher Level API for torch","text":"luz higher level API torch providing abstractions allow much less verbose training loops. package early stage development. Don’t use anything meaningful yet. ’s heavily inspired higher level frameworks deep learning, cite : FastAI: heavily inspired FastAI library, specially Learner object callbacks API. Keras: also heavily inspired Keras, specially callback names, lightning module interface similar compile . PyTorch Lightning: idea luz_module subclass nn_module inspired LightningModule object lightning. HuggingFace Accelerate: internal device placement API heavily inspired Accelerate, much modest features. Currenly CPU Single GPU supported.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Higher Level API for torch","text":"can install released version luz CRAN :","code":"install.packages(\"luz\")"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Higher Level API for torch","text":"basic example shows solve common problem:","code":"library(luz) ## basic example code"},{"path":"/reference/accelerator.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an accelerator — accelerator","title":"Create an accelerator — accelerator","text":"Create accelerator","code":""},{"path":"/reference/accelerator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an accelerator — accelerator","text":"","code":"accelerator(device_placement = TRUE, cpu = FALSE)"},{"path":"/reference/accelerator.html","id":"pkg-arg-device_placement","dir":"Reference","previous_headings":"","what":"device_placement (argument)","title":"Create an accelerator — accelerator","text":"device_placement (logical) whether accelerator object handle device placement. Default: TRUE","code":""},{"path":"/reference/accelerator.html","id":"pkg-arg-cpu","dir":"Reference","previous_headings":"","what":"cpu (argument)","title":"Create an accelerator — accelerator","text":"cpu (logical) whether training procedure run CPU.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a nn_module — fit.luz_module_generator","title":"Fit a nn_module — fit.luz_module_generator","text":"Fit nn_module","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a nn_module — fit.luz_module_generator","text":"","code":"# S3 method for luz_module_generator fit(   module,   data,   epochs = 10,   callbacks = NULL,   valid_data = NULL,   accelerator = NULL,   verbose = NULL )"},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-module","dir":"Reference","previous_headings":"","what":"module (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"module nn_module setup().","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-data","dir":"Reference","previous_headings":"","what":"data (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"data (dataloader) dataloader created torch::dataloader() used training model. dataloader must return list 2 items. first item used input module second used target loss function.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-epochs","dir":"Reference","previous_headings":"","what":"epochs (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"epochs (int) number epochs training model.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-callbacks","dir":"Reference","previous_headings":"","what":"callbacks (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"callbacks (list, optional) list callbacks defined luz_callback() called training procedure.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-valid_data","dir":"Reference","previous_headings":"","what":"valid_data (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"valid_data (dataloader, optional) dataloader created torch::dataloader() used validation procedure.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-accelerator","dir":"Reference","previous_headings":"","what":"accelerator (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"accelerator (accelerator, optional) optional accelerator() object used configure device placement components like nn_modules, optimizers batches data.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-verbose","dir":"Reference","previous_headings":"","what":"verbose (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"verbose (logical, optional) optional boolean value indicating fitting procedure emmit output console training. default, produce output interactive() TRUE, otherwise print console.","code":""},{"path":"/reference/luz_callback.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new callback — luz_callback","title":"Create a new callback — luz_callback","text":"Create new callback","code":""},{"path":"/reference/luz_callback.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new callback — luz_callback","text":"","code":"luz_callback(   name,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame() )"},{"path":"/reference/luz_callback.html","id":"pkg-arg-name","dir":"Reference","previous_headings":"","what":"name (argument)","title":"Create a new callback — luz_callback","text":"name nm","code":""},{"path":"/reference/luz_callback.html","id":"pkg-arg-...","dir":"Reference","previous_headings":"","what":"... (argument)","title":"Create a new callback — luz_callback","text":"... public methods","code":""},{"path":"/reference/luz_callback.html","id":"pkg-arg-private","dir":"Reference","previous_headings":"","what":"private (argument)","title":"Create a new callback — luz_callback","text":"private optional list private members, can functions non-functions.","code":""},{"path":"/reference/luz_callback.html","id":"pkg-arg-active","dir":"Reference","previous_headings":"","what":"active (argument)","title":"Create a new callback — luz_callback","text":"active optional list active binding functions.","code":""},{"path":"/reference/luz_callback.html","id":"pkg-arg-parent_env","dir":"Reference","previous_headings":"","what":"parent_env (argument)","title":"Create a new callback — luz_callback","text":"parent_env environment use parent newly-created objects.","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/set_hparams.html","id":null,"dir":"Reference","previous_headings":"","what":"Set hyper-parameter of a module — set_hparams","title":"Set hyper-parameter of a module — set_hparams","text":"function used define hyper-parameters calling fit luz_modules.","code":""},{"path":"/reference/set_hparams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set hyper-parameter of a module — set_hparams","text":"","code":"set_hparams(module, ...)"},{"path":"/reference/set_hparams.html","id":"pkg-arg-module","dir":"Reference","previous_headings":"","what":"module (argument)","title":"Set hyper-parameter of a module — set_hparams","text":"module nn_module setup().","code":""},{"path":"/reference/set_hparams.html","id":"pkg-arg-...","dir":"Reference","previous_headings":"","what":"... (argument)","title":"Set hyper-parameter of a module — set_hparams","text":"... parameters set used initialize nn_module, ie passed unchanged initialize method base nn_module.","code":""},{"path":"/reference/set_opt_hparams.html","id":null,"dir":"Reference","previous_headings":"","what":"Set optimizer hyper-parameters — set_opt_hparams","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"function used define hyper-parameters optimizer initialization method.","code":""},{"path":"/reference/set_opt_hparams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"","code":"set_opt_hparams(module, ...)"},{"path":"/reference/set_opt_hparams.html","id":"pkg-arg-module","dir":"Reference","previous_headings":"","what":"module (argument)","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"module nn_module setup().","code":""},{"path":"/reference/set_opt_hparams.html","id":"pkg-arg-...","dir":"Reference","previous_headings":"","what":"... (argument)","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"... parameters passed used initialize optimizers. example, optimizer optim_adam pass lr=0.1, optim_adam function called optim_adam(parameters, lr=0.1) fitting model.","code":""},{"path":"/reference/setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Set's up a nn_module to use with luz — setup","title":"Set's up a nn_module to use with luz — setup","text":"setup function used set important attributes method nn_modules used Luz.","code":""},{"path":"/reference/setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set's up a nn_module to use with luz — setup","text":"","code":"setup(module, loss = NULL, optimizer = NULL, metrics = NULL)"},{"path":"/reference/setup.html","id":"pkg-arg-module","dir":"Reference","previous_headings":"","what":"module (argument)","title":"Set's up a nn_module to use with luz — setup","text":"module (nn_module) nn_module want set .","code":""},{"path":"/reference/setup.html","id":"pkg-arg-loss","dir":"Reference","previous_headings":"","what":"loss (argument)","title":"Set's up a nn_module to use with luz — setup","text":"loss (function, optional) optional function signature function(input, target). requires nn_module implement method called loss.","code":""},{"path":"/reference/setup.html","id":"pkg-arg-optimizer","dir":"Reference","previous_headings":"","what":"optimizer (argument)","title":"Set's up a nn_module to use with luz — setup","text":"optimizer (torch_optimizer, optional) function signature function(parameters, ...) used initialize optimizer given model parameters.","code":""},{"path":"/reference/setup.html","id":"pkg-arg-metrics","dir":"Reference","previous_headings":"","what":"metrics (argument)","title":"Set's up a nn_module to use with luz — setup","text":"metrics (list, optional) list metrics tracked training procedure.","code":""},{"path":"/reference/setup.html","id":"section-details","dir":"Reference","previous_headings":"","what":"Details","title":"Set's up a nn_module to use with luz — setup","text":"makes sure module necessary ingredients order fitted.","code":""}]
